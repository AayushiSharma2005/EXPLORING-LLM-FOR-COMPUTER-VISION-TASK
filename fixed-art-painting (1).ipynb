{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9545143,"sourceType":"datasetVersion","datasetId":5815134}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nimport os\n\nroot_dir = \"/kaggle/input/pacs-dataset/kfold\"\nall_domains = ['sketch', 'cartoon', 'photo', 'art_painting']\n\nfor domain in all_domains:\n    folder = os.path.join(root_dir, domain)\n    dataset = ImageFolder(folder)\n    labels = [label for _, label in dataset.samples]\n    print(f\"{domain}: Classes = {dataset.classes}\")\n    print(f\"{domain}: Max Label = {max(labels)}, Unique Labels = {sorted(set(labels))}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T13:30:28.010498Z","iopub.execute_input":"2025-07-21T13:30:28.011059Z","iopub.status.idle":"2025-07-21T13:30:33.492673Z","shell.execute_reply.started":"2025-07-21T13:30:28.011032Z","shell.execute_reply":"2025-07-21T13:30:33.491845Z"}},"outputs":[{"name":"stdout","text":"sketch: Classes = ['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\nsketch: Max Label = 6, Unique Labels = [0, 1, 2, 3, 4, 5, 6]\n\ncartoon: Classes = ['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\ncartoon: Max Label = 6, Unique Labels = [0, 1, 2, 3, 4, 5, 6]\n\nphoto: Classes = ['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\nphoto: Max Label = 6, Unique Labels = [0, 1, 2, 3, 4, 5, 6]\n\nart_painting: Classes = ['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\nart_painting: Max Label = 6, Unique Labels = [0, 1, 2, 3, 4, 5, 6]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ✅ Full Updated Code with GRL Fix for Domain Labels\n\nimport os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms\nfrom torchvision.datasets import ImageFolder\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n# ============================\n# ✅ Reproducibility\n# ============================\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Using device:\", device)\n\n# ============================\n# ✅ Config\n# ============================\nroot_dir = \"/kaggle/input/pacs-dataset/kfold\"\ntrain_domains = ['sketch', 'cartoon', 'photo']\ntest_domain = 'art_painting'\ndomain_to_idx_train = {d: i for i, d in enumerate(train_domains)}\ndomain_to_idx_full = {'art_painting':0, 'cartoon':1, 'photo':2, 'sketch':3}\n\nbatch_size = 32\nnum_classes = 7\nlr = 5e-5\nmax_epochs = 50\npatience = 10\nalpha_mixup = 0.4\ngamma_margin = 0.5\nlambda_domain = 1.0\nlambda_margin = 0.2\n\n# ============================\n# ✅ Transforms\n# ============================\ntransform_train = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomResizedCrop((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])\n\n# ============================\n# ✅ Dataset\n# ============================\nclass PACSDomainDataset(Dataset):\n    def __init__(self, samples, labels, domain_labels, transform):\n        self.samples = samples\n        self.labels = labels\n        self.domains = domain_labels\n        self.transform = transform\n    def __len__(self): return len(self.samples)\n    def __getitem__(self, i):\n        img = Image.open(self.samples[i]).convert('RGB')\n        if self.transform: img = self.transform(img)\n        return img, self.labels[i], self.domains[i]\n\ntrain_samples_all, train_labels_all, train_domains_all = [], [], []\nval_samples_all, val_labels_all, val_domains_all = [], [], []\n\nfor d in train_domains:\n    folder = os.path.join(root_dir, d)\n    domain_idx = domain_to_idx_train[d]\n    data = ImageFolder(folder)\n    paths = [s[0] for s in data.samples]\n    labels = [s[1] for s in data.samples]\n    train_idx, val_idx = train_test_split(range(len(paths)), test_size=0.2, stratify=labels, random_state=seed)\n    for idx in train_idx:\n        train_samples_all.append(paths[idx])\n        train_labels_all.append(labels[idx])\n        train_domains_all.append(domain_idx)\n    for idx in val_idx:\n        val_samples_all.append(paths[idx])\n        val_labels_all.append(labels[idx])\n        val_domains_all.append(domain_idx)\n\ntrain_dataset = PACSDomainDataset(train_samples_all, train_labels_all, train_domains_all, transform_train)\nval_dataset = PACSDomainDataset(val_samples_all, val_labels_all, val_domains_all, transform_test)\n\ntest_paths = [s[0] for s in ImageFolder(os.path.join(root_dir, test_domain)).samples]\ntest_labels = [s[1] for s in ImageFolder(os.path.join(root_dir, test_domain)).samples]\ntest_domains = [domain_to_idx_full[test_domain]] * len(test_paths)\ntest_dataset = PACSDomainDataset(test_paths, test_labels, test_domains, transform_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\nprint(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n\n# ============================\n# ✅ GRL\n# ============================\nclass GradReverse(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x, lambd):\n        ctx.lambd = lambd\n        return x.view_as(x)\n    @staticmethod\n    def backward(ctx, grad_output):\n        return grad_output.neg() * ctx.lambd, None\n\nclass GRL(nn.Module):\n    def __init__(self, lambd=1.0):\n        super().__init__()\n        self.lambd = lambd\n    def forward(self, x):\n        return GradReverse.apply(x, self.lambd)\n\n# ============================\n# ✅ Models\n# ============================\nclass FIXEDFeatureExtractor(nn.Module):\n    def __init__(self, backbone, feat_dim):\n        super().__init__()\n        self.backbone = backbone\n        self.domain_invariant_proj = nn.Sequential(\n            nn.Linear(feat_dim, feat_dim),\n            nn.BatchNorm1d(feat_dim),\n            nn.ReLU(),\n            nn.Dropout(0.1)\n        )\n    def forward(self, x):\n        raw_feats = self.backbone(x)\n        inv_feats = self.domain_invariant_proj(raw_feats)\n        return raw_feats, inv_feats\n\nclass FIXEDClassifier(nn.Module):\n    def __init__(self, feat_dim, num_classes):\n        super().__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(feat_dim, feat_dim//2),\n            nn.BatchNorm1d(feat_dim//2),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(feat_dim//2, num_classes)\n        )\n    def forward(self, x): return self.fc(x)\n\nclass DomainClassifier(nn.Module):\n    def __init__(self, feat_dim, num_domains):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(feat_dim, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.1),\n            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.1),\n            nn.Linear(256, num_domains)\n        )\n    def forward(self, x): return self.net(x)\n\n# ============================\n# ✅ Init models (ResNet18)\n# ============================\nbackbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\nfeat_dim = backbone.fc.in_features\nbackbone.fc = nn.Identity()\n\nfeature_extractor = FIXEDFeatureExtractor(backbone, feat_dim).to(device)\nclassifier = FIXEDClassifier(feat_dim, num_classes).to(device)\ndomain_classifier = DomainClassifier(feat_dim, len(train_domains)).to(device)\ngrl = GRL()\n\noptimizer = torch.optim.Adam([\n    {'params': feature_extractor.parameters(), 'lr': lr},\n    {'params': classifier.parameters(), 'lr': lr},\n    {'params': domain_classifier.parameters(), 'lr': lr * 10}\n], weight_decay=1e-4)\n\ncriterion_cls = nn.CrossEntropyLoss()\ncriterion_domain = nn.CrossEntropyLoss()\n\n# ============================\n# ✅ Loss helpers\n# ============================\ndef large_margin_loss(logits, labels, gamma=0.5):\n    correct = logits.gather(1, labels.view(-1,1)).squeeze()\n    mask = torch.ones_like(logits).scatter(1, labels.view(-1,1), 0.0)\n    max_incorrect = (logits*mask + (1-mask)*(-1e8)).max(1)[0]\n    return F.relu(gamma + max_incorrect - correct).mean()\n\ndef mixup_data(features, labels, alpha=0.4):\n    lam = np.random.beta(alpha, alpha)\n    index = torch.randperm(features.size(0)).to(device)\n    mixed = lam * features + (1-lam) * features[index]\n    return mixed, labels, labels[index], lam\n\ndef mixup_criterion(crit, preds, y_a, y_b, lam):\n    return lam * crit(preds, y_a) + (1-lam) * crit(preds, y_b)\n\n# ============================\n# ✅ Training with patience\n# ============================\nbest_val_acc = 0.0\nepochs_no_improve = 0\n\nfor epoch in range(1, max_epochs+1):\n    feature_extractor.train()\n    classifier.train()\n    domain_classifier.train()\n    total_loss = 0.0\n\n    for imgs, labels, d_labels in train_loader:\n        imgs, labels, d_labels = imgs.to(device), labels.to(device), d_labels.to(device)\n        optimizer.zero_grad()\n        raw_feats, inv_feats = feature_extractor(imgs)\n        mixed_feats, y_a, y_b, lam = mixup_data(inv_feats, labels, alpha_mixup)\n        cls_logits = classifier(mixed_feats)\n        loss_cls = mixup_criterion(criterion_cls, cls_logits, y_a, y_b, lam)\n        loss_margin = large_margin_loss(cls_logits, y_a, gamma_margin)\n        dom_logits = domain_classifier(grl(raw_feats))\n        loss_domain = criterion_domain(dom_logits, d_labels)\n        loss = loss_cls + lambda_domain * loss_domain + lambda_margin * loss_margin\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    feature_extractor.eval()\n    classifier.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for imgs, labels, _ in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            _, feats = feature_extractor(imgs)\n            preds = classifier(feats).argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    val_acc = 100.0 * correct / total\n\n    print(f\"Epoch {epoch}/{max_epochs} - Train Loss: {total_loss/len(train_loader):.4f} | Val Acc: {val_acc:.2f}%\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        epochs_no_improve = 0\n        torch.save({\n            'feature_extractor': feature_extractor.state_dict(),\n            'classifier': classifier.state_dict()\n        }, \"best_model.pth\")\n        print(f\"  ✅ New best val acc: {best_val_acc:.2f}% (model saved)\")\n    else:\n        epochs_no_improve += 1\n        print(f\"  No improvement. Patience: {epochs_no_improve}/{patience}\")\n        if epochs_no_improve >= patience:\n            print(f\"⏹ Early stopping at epoch {epoch}. Best Val Acc: {best_val_acc:.2f}%\")\n            break\n\n# ============================\n# ✅ Final test evaluation\n# ============================\nckpt = torch.load(\"best_model.pth\", map_location=device)\nfeature_extractor.load_state_dict(ckpt['feature_extractor'])\nclassifier.load_state_dict(ckpt['classifier'])\nfeature_extractor.eval()\nclassifier.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for imgs, labels, _ in test_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        _, feats = feature_extractor(imgs)\n        preds = classifier(feats).argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\ntest_acc = 100.0 * correct / total\nprint(f\"\\n✅ Final Test Accuracy on {test_domain}: {test_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T13:51:58.979544Z","iopub.execute_input":"2025-07-21T13:51:58.980374Z","iopub.status.idle":"2025-07-21T14:13:02.289464Z","shell.execute_reply.started":"2025-07-21T13:51:58.980343Z","shell.execute_reply":"2025-07-21T14:13:02.288675Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nTrain size: 6354, Val size: 1589, Test size: 2048\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 209MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50 - Train Loss: 2.4465 | Val Acc: 76.15%\n  ✅ New best val acc: 76.15% (model saved)\nEpoch 2/50 - Train Loss: 2.3817 | Val Acc: 80.11%\n  ✅ New best val acc: 80.11% (model saved)\nEpoch 3/50 - Train Loss: 2.2223 | Val Acc: 88.99%\n  ✅ New best val acc: 88.99% (model saved)\nEpoch 4/50 - Train Loss: 2.2552 | Val Acc: 89.24%\n  ✅ New best val acc: 89.24% (model saved)\nEpoch 5/50 - Train Loss: 2.1539 | Val Acc: 90.43%\n  ✅ New best val acc: 90.43% (model saved)\nEpoch 6/50 - Train Loss: 2.0911 | Val Acc: 92.32%\n  ✅ New best val acc: 92.32% (model saved)\nEpoch 7/50 - Train Loss: 2.1173 | Val Acc: 92.07%\n  No improvement. Patience: 1/10\nEpoch 8/50 - Train Loss: 2.0830 | Val Acc: 93.14%\n  ✅ New best val acc: 93.14% (model saved)\nEpoch 9/50 - Train Loss: 2.0859 | Val Acc: 91.94%\n  No improvement. Patience: 1/10\nEpoch 10/50 - Train Loss: 2.0795 | Val Acc: 93.08%\n  No improvement. Patience: 2/10\nEpoch 11/50 - Train Loss: 2.0318 | Val Acc: 93.83%\n  ✅ New best val acc: 93.83% (model saved)\nEpoch 12/50 - Train Loss: 2.0187 | Val Acc: 93.08%\n  No improvement. Patience: 1/10\nEpoch 13/50 - Train Loss: 2.0163 | Val Acc: 94.02%\n  ✅ New best val acc: 94.02% (model saved)\nEpoch 14/50 - Train Loss: 1.9948 | Val Acc: 94.27%\n  ✅ New best val acc: 94.27% (model saved)\nEpoch 15/50 - Train Loss: 1.9541 | Val Acc: 93.14%\n  No improvement. Patience: 1/10\nEpoch 16/50 - Train Loss: 1.9874 | Val Acc: 93.96%\n  No improvement. Patience: 2/10\nEpoch 17/50 - Train Loss: 1.9907 | Val Acc: 93.64%\n  No improvement. Patience: 3/10\nEpoch 18/50 - Train Loss: 1.9624 | Val Acc: 94.59%\n  ✅ New best val acc: 94.59% (model saved)\nEpoch 19/50 - Train Loss: 1.9488 | Val Acc: 94.34%\n  No improvement. Patience: 1/10\nEpoch 20/50 - Train Loss: 1.9949 | Val Acc: 93.90%\n  No improvement. Patience: 2/10\nEpoch 21/50 - Train Loss: 1.9633 | Val Acc: 94.02%\n  No improvement. Patience: 3/10\nEpoch 22/50 - Train Loss: 1.9010 | Val Acc: 95.59%\n  ✅ New best val acc: 95.59% (model saved)\nEpoch 23/50 - Train Loss: 1.8927 | Val Acc: 95.28%\n  No improvement. Patience: 1/10\nEpoch 24/50 - Train Loss: 1.9063 | Val Acc: 94.78%\n  No improvement. Patience: 2/10\nEpoch 25/50 - Train Loss: 1.8931 | Val Acc: 94.90%\n  No improvement. Patience: 3/10\nEpoch 26/50 - Train Loss: 1.9001 | Val Acc: 95.78%\n  ✅ New best val acc: 95.78% (model saved)\nEpoch 27/50 - Train Loss: 1.8698 | Val Acc: 94.34%\n  No improvement. Patience: 1/10\nEpoch 28/50 - Train Loss: 1.8980 | Val Acc: 95.41%\n  No improvement. Patience: 2/10\nEpoch 29/50 - Train Loss: 1.9028 | Val Acc: 95.28%\n  No improvement. Patience: 3/10\nEpoch 30/50 - Train Loss: 1.8736 | Val Acc: 95.41%\n  No improvement. Patience: 4/10\nEpoch 31/50 - Train Loss: 1.8455 | Val Acc: 94.27%\n  No improvement. Patience: 5/10\nEpoch 32/50 - Train Loss: 1.8788 | Val Acc: 94.52%\n  No improvement. Patience: 6/10\nEpoch 33/50 - Train Loss: 1.8929 | Val Acc: 95.09%\n  No improvement. Patience: 7/10\nEpoch 34/50 - Train Loss: 1.8225 | Val Acc: 94.84%\n  No improvement. Patience: 8/10\nEpoch 35/50 - Train Loss: 1.8302 | Val Acc: 95.47%\n  No improvement. Patience: 9/10\nEpoch 36/50 - Train Loss: 1.8517 | Val Acc: 95.03%\n  No improvement. Patience: 10/10\n⏹ Early stopping at epoch 36. Best Val Acc: 95.78%\n\n✅ Final Test Accuracy on art_painting: 76.37%\n","output_type":"stream"}],"execution_count":1}]}