{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/mlfoundations/open_clip.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T11:47:50.200240Z","iopub.execute_input":"2025-07-18T11:47:50.200433Z","iopub.status.idle":"2025-07-18T11:49:06.775206Z","shell.execute_reply.started":"2025-07-18T11:47:50.200416Z","shell.execute_reply":"2025-07-18T11:49:06.774443Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/mlfoundations/open_clip.git\n  Cloning https://github.com/mlfoundations/open_clip.git to /tmp/pip-req-build-ilyu5c_7\n  Running command git clone --filter=blob:none --quiet https://github.com/mlfoundations/open_clip.git /tmp/pip-req-build-ilyu5c_7\n  Resolved https://github.com/mlfoundations/open_clip.git to commit a87f11eaf354000d2736580855ae0d9b76ad2a22\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.32.0) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.32.0) (0.21.0+cu124)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.32.0) (2024.11.6)\nCollecting ftfy (from open_clip_torch==2.32.0)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.32.0) (4.67.1)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.32.0) (0.33.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.32.0) (0.5.3)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.32.0) (1.0.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9.0->open_clip_torch==2.32.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch==2.32.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch==2.32.0) (1.3.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch==2.32.0) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch==2.32.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch==2.32.0) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch==2.32.0) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch==2.32.0) (1.1.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch==2.32.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch==2.32.0) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch==2.32.0) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch==2.32.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch==2.32.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch==2.32.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch==2.32.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch==2.32.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch==2.32.0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch==2.32.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch==2.32.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch==2.32.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch==2.32.0) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch==2.32.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch==2.32.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->open_clip_torch==2.32.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->open_clip_torch==2.32.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->open_clip_torch==2.32.0) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: open_clip_torch\n  Building wheel for open_clip_torch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for open_clip_torch: filename=open_clip_torch-2.32.0-py3-none-any.whl size=1534723 sha256=d9bd74dd2bba879d2c85330486757d1fc0254b4be498adb46c6fc589dcd59dce\n  Stored in directory: /tmp/pip-ephem-wheel-cache-m3au_mr8/wheels/d8/9b/13/a8a2e5c224e89773936b77a6cabeef655305344e23f7b02065\nSuccessfully built open_clip_torch\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, open_clip_torch\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open_clip_torch-2.32.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**no of samples**","metadata":{}},{"cell_type":"code","source":"import os\n\nroot_dir = \"/kaggle/input/pacs-dataset/kfold\"\ndomains = [\"photo\", \"art_painting\", \"cartoon\", \"sketch\"]\n\nfor domain in domains:\n    domain_path = os.path.join(root_dir, domain)\n    count = 0\n    for cls in os.listdir(domain_path):\n        cls_path = os.path.join(domain_path, cls)\n        count += len(os.listdir(cls_path))\n    print(f\"{domain} has {count} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T11:49:06.777013Z","iopub.execute_input":"2025-07-18T11:49:06.777235Z","iopub.status.idle":"2025-07-18T11:49:07.155979Z","shell.execute_reply.started":"2025-07-18T11:49:06.777212Z","shell.execute_reply":"2025-07-18T11:49:07.155370Z"}},"outputs":[{"name":"stdout","text":"photo has 1670 images\nart_painting has 2048 images\ncartoon has 2344 images\nsketch has 3929 images\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**Multi-Domain Training with RN50 and ViT-B16 Backbones**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport open_clip\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nPACS_PATH = \"/kaggle/input/pacs-dataset/kfold\"\n\nclass CLIPMLPClassifier(nn.Module):\n    def __init__(self, clip_model, num_classes):\n        super().__init__()\n        self.clip = clip_model\n        self.mlp = nn.Sequential(\n            nn.Linear(self.clip.visual.output_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        with torch.no_grad():\n            feats = self.clip.encode_image(x)\n        return self.mlp(feats)\n\ndef get_loader(domains, root, transform, batch_size=32, shuffle=False):\n    dataset = []\n    for domain in domains:\n        ds = datasets.ImageFolder(os.path.join(root, domain), transform=transform)\n        dataset.extend(ds.samples)\n    base_ds = datasets.ImageFolder(os.path.join(root, domains[0]), transform=transform)\n    base_ds.samples = dataset\n    loader = DataLoader(base_ds, batch_size=batch_size, shuffle=shuffle)\n    return loader, len(base_ds.classes)\n\ntrain_domains = [\"photo\", \"sketch\", \"art_painting\"]\ntest_domain = \"cartoon\"\nresults = {}\n\nbackbones = ['RN50', 'ViT-B-16']\n\nfor backbone in backbones:\n    print(f\"\\n= Training with {backbone} =\")\n\n    clip_model, _, preprocess = open_clip.create_model_and_transforms(backbone, pretrained='openai')\n    clip_model.eval().to(device)\n    for param in clip_model.parameters():\n        param.requires_grad = False\n\n    train_loader, num_classes = get_loader(train_domains, PACS_PATH, preprocess, shuffle=True)\n    test_loader, _ = get_loader([test_domain], PACS_PATH, preprocess, shuffle=False)\n\n    model = CLIPMLPClassifier(clip_model, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.mlp.parameters(), lr=1e-4)\n\n    best_acc = 0\n    wait = 0\n    patience = 10\n\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n\n        for imgs, labels in tqdm(train_loader, desc=f\"[{backbone}] Epoch {epoch+1} - Training\"):\n            imgs, labels = imgs.to(device), labels.to(device)\n            logits = model(imgs)\n            loss = criterion(logits, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        print(f\"[{backbone}] Epoch {epoch+1} - Training Loss: {total_loss:.4f}\")\n\n        # Evaluation\n        model.eval()\n        correct, total = 0, 0\n        with torch.no_grad():\n            for imgs, labels in test_loader:\n                imgs, labels = imgs.to(device), labels.to(device)\n                outputs = model(imgs)\n                preds = torch.argmax(outputs, dim=1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n        acc = 100 * correct / total\n        print(f\"[{backbone}] Test Accuracy on '{test_domain}': {acc:.2f}%\")\n\n        if acc > best_acc:\n            best_acc = acc\n            wait = 0\n            print(f\"[{backbone}] Accuracy improved.\")\n        else:\n            wait += 1\n            print(f\"[{backbone}] No improvement. Wait count: {wait}/{patience}\")\n            if wait >= patience:\n                print(f\"[{backbone}] Early stopping triggered.\")\n                break\n\n    results[backbone] = best_acc\n    print(f\"[{backbone}] Best Accuracy Achieved: {best_acc:.2f}%\")\n\nprint(\"\\n= Summary of Test Accuracies =\")\nfor name, acc in results.items():\n    print(f\"{name:10s}: {acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T11:49:07.156695Z","iopub.execute_input":"2025-07-18T11:49:07.156870Z","iopub.status.idle":"2025-07-18T12:31:37.038031Z","shell.execute_reply.started":"2025-07-18T11:49:07.156855Z","shell.execute_reply":"2025-07-18T12:31:37.037331Z"}},"outputs":[{"name":"stdout","text":"\n= Training with RN50 =\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"open_clip_model.safetensors:   0%|          | 0.00/408M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fffe6f8527745fcb9b314a57e9da7f2"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/open_clip/factory.py:442: UserWarning: QuickGELU mismatch between final model config (quick_gelu=False) and pretrained tag 'openai' (quick_gelu=True).\n  warnings.warn(\n[RN50] Epoch 1 - Training: 100%|██████████| 239/239 [01:11<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 1 - Training Loss: 424.6849\n[RN50] Test Accuracy on 'cartoon': 59.64%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 2 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 2 - Training Loss: 312.1026\n[RN50] Test Accuracy on 'cartoon': 74.02%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 3 - Training: 100%|██████████| 239/239 [00:44<00:00,  5.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 3 - Training Loss: 231.8337\n[RN50] Test Accuracy on 'cartoon': 76.02%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 4 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 4 - Training Loss: 188.3210\n[RN50] Test Accuracy on 'cartoon': 77.52%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 5 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 5 - Training Loss: 161.7625\n[RN50] Test Accuracy on 'cartoon': 79.14%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 6 - Training: 100%|██████████| 239/239 [00:40<00:00,  5.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 6 - Training Loss: 147.1130\n[RN50] Test Accuracy on 'cartoon': 78.46%\n[RN50] No improvement. Wait count: 1/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 7 - Training: 100%|██████████| 239/239 [00:40<00:00,  5.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 7 - Training Loss: 135.6252\n[RN50] Test Accuracy on 'cartoon': 78.07%\n[RN50] No improvement. Wait count: 2/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 8 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 8 - Training Loss: 128.9197\n[RN50] Test Accuracy on 'cartoon': 79.39%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 9 - Training: 100%|██████████| 239/239 [00:40<00:00,  5.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 9 - Training Loss: 124.4329\n[RN50] Test Accuracy on 'cartoon': 79.78%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 10 - Training: 100%|██████████| 239/239 [00:40<00:00,  5.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 10 - Training Loss: 118.6082\n[RN50] Test Accuracy on 'cartoon': 79.65%\n[RN50] No improvement. Wait count: 1/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 11 - Training: 100%|██████████| 239/239 [00:40<00:00,  5.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 11 - Training Loss: 115.5327\n[RN50] Test Accuracy on 'cartoon': 78.92%\n[RN50] No improvement. Wait count: 2/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 12 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 12 - Training Loss: 110.8202\n[RN50] Test Accuracy on 'cartoon': 79.86%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 13 - Training: 100%|██████████| 239/239 [00:42<00:00,  5.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 13 - Training Loss: 110.6558\n[RN50] Test Accuracy on 'cartoon': 81.06%\n[RN50] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 14 - Training: 100%|██████████| 239/239 [00:45<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 14 - Training Loss: 104.8697\n[RN50] Test Accuracy on 'cartoon': 79.86%\n[RN50] No improvement. Wait count: 1/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 15 - Training: 100%|██████████| 239/239 [00:44<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 15 - Training Loss: 103.9631\n[RN50] Test Accuracy on 'cartoon': 81.02%\n[RN50] No improvement. Wait count: 2/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 16 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 16 - Training Loss: 104.0227\n[RN50] Test Accuracy on 'cartoon': 80.84%\n[RN50] No improvement. Wait count: 3/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 17 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 17 - Training Loss: 102.5895\n[RN50] Test Accuracy on 'cartoon': 79.86%\n[RN50] No improvement. Wait count: 4/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 18 - Training: 100%|██████████| 239/239 [00:40<00:00,  5.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 18 - Training Loss: 98.9410\n[RN50] Test Accuracy on 'cartoon': 80.25%\n[RN50] No improvement. Wait count: 5/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 19 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 19 - Training Loss: 99.8799\n[RN50] Test Accuracy on 'cartoon': 79.39%\n[RN50] No improvement. Wait count: 6/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 20 - Training: 100%|██████████| 239/239 [00:47<00:00,  5.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 20 - Training Loss: 97.2938\n[RN50] Test Accuracy on 'cartoon': 80.33%\n[RN50] No improvement. Wait count: 7/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 21 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 21 - Training Loss: 97.5575\n[RN50] Test Accuracy on 'cartoon': 80.84%\n[RN50] No improvement. Wait count: 8/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 22 - Training: 100%|██████████| 239/239 [00:41<00:00,  5.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 22 - Training Loss: 95.0696\n[RN50] Test Accuracy on 'cartoon': 79.91%\n[RN50] No improvement. Wait count: 9/10\n","output_type":"stream"},{"name":"stderr","text":"[RN50] Epoch 23 - Training: 100%|██████████| 239/239 [00:44<00:00,  5.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"[RN50] Epoch 23 - Training Loss: 95.7041\n[RN50] Test Accuracy on 'cartoon': 79.86%\n[RN50] No improvement. Wait count: 10/10\n[RN50] Early stopping triggered.\n[RN50] Best Accuracy Achieved: 81.06%\n\n= Training with ViT-B-16 =\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"open_clip_model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25edc827c1924345ae5a6efa2f477434"}},"metadata":{}},{"name":"stderr","text":"[ViT-B-16] Epoch 1 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 1 - Training Loss: 236.3461\n[ViT-B-16] Test Accuracy on 'cartoon': 98.38%\n[ViT-B-16] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 2 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 2 - Training Loss: 57.7756\n[ViT-B-16] Test Accuracy on 'cartoon': 98.63%\n[ViT-B-16] Accuracy improved.\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 3 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 3 - Training Loss: 37.0170\n[ViT-B-16] Test Accuracy on 'cartoon': 98.42%\n[ViT-B-16] No improvement. Wait count: 1/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 4 - Training: 100%|██████████| 239/239 [01:15<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 4 - Training Loss: 30.3771\n[ViT-B-16] Test Accuracy on 'cartoon': 98.42%\n[ViT-B-16] No improvement. Wait count: 2/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 5 - Training: 100%|██████████| 239/239 [01:22<00:00,  2.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 5 - Training Loss: 26.8525\n[ViT-B-16] Test Accuracy on 'cartoon': 98.34%\n[ViT-B-16] No improvement. Wait count: 3/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 6 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 6 - Training Loss: 24.5477\n[ViT-B-16] Test Accuracy on 'cartoon': 98.38%\n[ViT-B-16] No improvement. Wait count: 4/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 7 - Training: 100%|██████████| 239/239 [01:41<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 7 - Training Loss: 22.8588\n[ViT-B-16] Test Accuracy on 'cartoon': 98.29%\n[ViT-B-16] No improvement. Wait count: 5/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 8 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 8 - Training Loss: 21.5112\n[ViT-B-16] Test Accuracy on 'cartoon': 98.29%\n[ViT-B-16] No improvement. Wait count: 6/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 9 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 9 - Training Loss: 20.3005\n[ViT-B-16] Test Accuracy on 'cartoon': 98.34%\n[ViT-B-16] No improvement. Wait count: 7/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 10 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 10 - Training Loss: 19.3122\n[ViT-B-16] Test Accuracy on 'cartoon': 98.38%\n[ViT-B-16] No improvement. Wait count: 8/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 11 - Training: 100%|██████████| 239/239 [01:16<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 11 - Training Loss: 18.3867\n[ViT-B-16] Test Accuracy on 'cartoon': 98.38%\n[ViT-B-16] No improvement. Wait count: 9/10\n","output_type":"stream"},{"name":"stderr","text":"[ViT-B-16] Epoch 12 - Training: 100%|██████████| 239/239 [01:17<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"[ViT-B-16] Epoch 12 - Training Loss: 17.8875\n[ViT-B-16] Test Accuracy on 'cartoon': 98.21%\n[ViT-B-16] No improvement. Wait count: 10/10\n[ViT-B-16] Early stopping triggered.\n[ViT-B-16] Best Accuracy Achieved: 98.63%\n\n= Summary of Test Accuracies =\nRN50      : 81.06%\nViT-B-16  : 98.63%\n","output_type":"stream"}],"execution_count":3}]}