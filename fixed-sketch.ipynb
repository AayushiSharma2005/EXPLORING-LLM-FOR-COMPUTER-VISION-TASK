{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9545143,"sourceType":"datasetVersion","datasetId":5815134}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms\nfrom torchvision.datasets import ImageFolder\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Using device:\", device)\n\nroot_dir = \"/kaggle/input/pacs-dataset/kfold\"\ntrain_domains = ['cartoon', 'art_painting', 'photo']\ntest_domain = 'sketch'\ndomain_to_idx_train = {d: i for i, d in enumerate(train_domains)}\ndomain_to_idx_full = {'art_painting':0, 'cartoon':1, 'photo':2, 'sketch':3}\n\nbatch_size = 32\nnum_classes = 7\nlr = 5e-5\nmax_epochs = 50\npatience = 10\nalpha_mixup = 0.4\ngamma_margin = 0.5\nlambda_domain = 1.0\nlambda_margin = 0.2\n\ntransform_train = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomResizedCrop((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])\n\nclass PACSDomainDataset(Dataset):\n    def __init__(self, samples, labels, domain_labels, transform):\n        self.samples = samples\n        self.labels = labels\n        self.domains = domain_labels\n        self.transform = transform\n    def __len__(self):\n        return len(self.samples)\n    def __getitem__(self, i):\n        img = Image.open(self.samples[i]).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, self.labels[i], self.domains[i]\n\ntrain_samples_all, train_labels_all, train_domains_all = [], [], []\nval_samples_all, val_labels_all, val_domains_all = [], [], []\n\nfor d in train_domains:\n    folder = os.path.join(root_dir, d)\n    domain_idx = domain_to_idx_train[d]\n    data = ImageFolder(folder)\n    paths = [s[0] for s in data.samples]\n    labels = [s[1] for s in data.samples]\n    train_idx, val_idx = train_test_split(range(len(paths)), test_size=0.2, stratify=labels, random_state=seed)\n    for idx in train_idx:\n        train_samples_all.append(paths[idx])\n        train_labels_all.append(labels[idx])\n        train_domains_all.append(domain_idx)\n    for idx in val_idx:\n        val_samples_all.append(paths[idx])\n        val_labels_all.append(labels[idx])\n        val_domains_all.append(domain_idx)\n\ntrain_dataset = PACSDomainDataset(train_samples_all, train_labels_all, train_domains_all, transform_train)\nval_dataset = PACSDomainDataset(val_samples_all, val_labels_all, val_domains_all, transform_test)\n\ntest_paths = [s[0] for s in ImageFolder(os.path.join(root_dir, test_domain)).samples]\ntest_labels = [s[1] for s in ImageFolder(os.path.join(root_dir, test_domain)).samples]\ntest_domains = [domain_to_idx_full[test_domain]] * len(test_paths)\ntest_dataset = PACSDomainDataset(test_paths, test_labels, test_domains, transform_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\nprint(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n\nclass GradReverse(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x, lambd):\n        ctx.lambd = lambd\n        return x.view_as(x)\n    @staticmethod\n    def backward(ctx, grad_output):\n        return grad_output.neg() * ctx.lambd, None\n\nclass GRL(nn.Module):\n    def __init__(self, lambd=1.0):\n        super().__init__()\n        self.lambd = lambd\n    def forward(self, x):\n        return GradReverse.apply(x, self.lambd)\n\nclass FIXEDFeatureExtractor(nn.Module):\n    def __init__(self, backbone, feat_dim):\n        super().__init__()\n        self.backbone = backbone\n        self.domain_invariant_proj = nn.Sequential(\n            nn.Linear(feat_dim, feat_dim),\n            nn.BatchNorm1d(feat_dim),\n            nn.ReLU(),\n            nn.Dropout(0.1)\n        )\n    def forward(self, x):\n        raw_feats = self.backbone(x)\n        inv_feats = self.domain_invariant_proj(raw_feats)\n        return raw_feats, inv_feats\n\nclass FIXEDClassifier(nn.Module):\n    def __init__(self, feat_dim, num_classes):\n        super().__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(feat_dim, feat_dim//2),\n            nn.BatchNorm1d(feat_dim//2),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(feat_dim//2, num_classes)\n        )\n    def forward(self, x):\n        return self.fc(x)\n\nclass DomainClassifier(nn.Module):\n    def __init__(self, feat_dim, num_domains):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(feat_dim, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.1),\n            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.1),\n            nn.Linear(256, num_domains)\n        )\n    def forward(self, x):\n        return self.net(x)\n\nbackbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\nfeat_dim = backbone.fc.in_features\nbackbone.fc = nn.Identity()\n\nfeature_extractor = FIXEDFeatureExtractor(backbone, feat_dim).to(device)\nclassifier = FIXEDClassifier(feat_dim, num_classes).to(device)\ndomain_classifier = DomainClassifier(feat_dim, len(train_domains)).to(device)\ngr = GRL()\n\noptimizer = torch.optim.Adam([\n    {'params': feature_extractor.parameters(), 'lr': lr},\n    {'params': classifier.parameters(), 'lr': lr},\n    {'params': domain_classifier.parameters(), 'lr': lr * 10}\n], weight_decay=1e-4)\n\ncriterion_cls = nn.CrossEntropyLoss()\ncriterion_domain = nn.CrossEntropyLoss()\n\ndef large_margin_loss(logits, labels, gamma=0.5):\n    correct = logits.gather(1, labels.view(-1,1)).squeeze()\n    mask = torch.ones_like(logits).scatter(1, labels.view(-1,1), 0.0)\n    max_incorrect = (logits*mask + (1-mask)*(-1e8)).max(1)[0]\n    return F.relu(gamma + max_incorrect - correct).mean()\n\ndef mixup_data(features, labels, alpha=0.4):\n    lam = np.random.beta(alpha, alpha)\n    index = torch.randperm(features.size(0)).to(device)\n    mixed = lam * features + (1-lam) * features[index]\n    return mixed, labels, labels[index], lam\n\ndef mixup_criterion(crit, preds, y_a, y_b, lam):\n    return lam * crit(preds, y_a) + (1-lam) * crit(preds, y_b)\n\nbest_val_acc = 0.0\nepochs_no_improve = 0\n\nfor epoch in range(1, max_epochs+1):\n    feature_extractor.train()\n    classifier.train()\n    domain_classifier.train()\n    total_loss = 0.0\n\n    for imgs, labels, d_labels in train_loader:\n        imgs, labels, d_labels = imgs.to(device), labels.to(device), d_labels.to(device)\n        optimizer.zero_grad()\n        raw_feats, inv_feats = feature_extractor(imgs)\n        mixed_feats, y_a, y_b, lam = mixup_data(inv_feats, labels, alpha_mixup)\n        cls_logits = classifier(mixed_feats)\n        loss_cls = mixup_criterion(criterion_cls, cls_logits, y_a, y_b, lam)\n        loss_margin = large_margin_loss(cls_logits, y_a, gamma_margin)\n        dom_logits = domain_classifier(gr(raw_feats))\n        loss_domain = criterion_domain(dom_logits, d_labels)\n        loss = loss_cls + lambda_domain * loss_domain + lambda_margin * loss_margin\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    feature_extractor.eval()\n    classifier.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for imgs, labels, _ in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            _, feats = feature_extractor(imgs)\n            preds = classifier(feats).argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    val_acc = 100.0 * correct / total\n\n    print(f\"Epoch {epoch}/{max_epochs} - Train Loss: {total_loss/len(train_loader):.4f} | Val Acc: {val_acc:.2f}%\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        epochs_no_improve = 0\n        torch.save({\n            'feature_extractor': feature_extractor.state_dict(),\n            'classifier': classifier.state_dict()\n        }, \"best_model.pth\")\n        print(f\"   New best val acc: {best_val_acc:.2f}% (model saved)\")\n    else:\n        epochs_no_improve += 1\n        print(f\"  No improvement. Patience: {epochs_no_improve}/{patience}\")\n        if epochs_no_improve >= patience:\n            print(f\" Early stopping at epoch {epoch}. Best Val Acc: {best_val_acc:.2f}%\")\n            break\n\nckpt = torch.load(\"best_model.pth\", map_location=device)\nfeature_extractor.load_state_dict(ckpt['feature_extractor'])\nclassifier.load_state_dict(ckpt['classifier'])\nfeature_extractor.eval()\nclassifier.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for imgs, labels, _ in test_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        _, feats = feature_extractor(imgs)\n        preds = classifier(feats).argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\ntest_acc = 100.0 * correct / total\nprint(f\"\\n Final Test Accuracy on {test_domain}: {test_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T02:38:32.806323Z","iopub.execute_input":"2025-07-23T02:38:32.806624Z","iopub.status.idle":"2025-07-23T02:55:27.522376Z","shell.execute_reply.started":"2025-07-23T02:38:32.806595Z","shell.execute_reply":"2025-07-23T02:55:27.521539Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nTrain size: 4849, Val size: 1213, Test size: 3929\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 187MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50 - Train Loss: 2.3909 | Val Acc: 78.15%\n   New best val acc: 78.15% (model saved)\nEpoch 2/50 - Train Loss: 2.3167 | Val Acc: 88.62%\n   New best val acc: 88.62% (model saved)\nEpoch 3/50 - Train Loss: 2.2464 | Val Acc: 88.05%\n  No improvement. Patience: 1/10\nEpoch 4/50 - Train Loss: 2.2134 | Val Acc: 90.85%\n   New best val acc: 90.85% (model saved)\nEpoch 5/50 - Train Loss: 2.2115 | Val Acc: 91.34%\n   New best val acc: 91.34% (model saved)\nEpoch 6/50 - Train Loss: 2.1766 | Val Acc: 91.92%\n   New best val acc: 91.92% (model saved)\nEpoch 7/50 - Train Loss: 2.0912 | Val Acc: 92.99%\n   New best val acc: 92.99% (model saved)\nEpoch 8/50 - Train Loss: 2.0843 | Val Acc: 93.32%\n   New best val acc: 93.32% (model saved)\nEpoch 9/50 - Train Loss: 2.1065 | Val Acc: 93.08%\n  No improvement. Patience: 1/10\nEpoch 10/50 - Train Loss: 2.1022 | Val Acc: 92.75%\n  No improvement. Patience: 2/10\nEpoch 11/50 - Train Loss: 2.0564 | Val Acc: 92.17%\n  No improvement. Patience: 3/10\nEpoch 12/50 - Train Loss: 2.0464 | Val Acc: 93.73%\n   New best val acc: 93.73% (model saved)\nEpoch 13/50 - Train Loss: 2.0643 | Val Acc: 93.73%\n  No improvement. Patience: 1/10\nEpoch 14/50 - Train Loss: 2.0552 | Val Acc: 94.23%\n   New best val acc: 94.23% (model saved)\nEpoch 15/50 - Train Loss: 2.0290 | Val Acc: 92.33%\n  No improvement. Patience: 1/10\nEpoch 16/50 - Train Loss: 2.0258 | Val Acc: 94.23%\n  No improvement. Patience: 2/10\nEpoch 17/50 - Train Loss: 2.0056 | Val Acc: 93.40%\n  No improvement. Patience: 3/10\nEpoch 18/50 - Train Loss: 2.0254 | Val Acc: 93.82%\n  No improvement. Patience: 4/10\nEpoch 19/50 - Train Loss: 1.9705 | Val Acc: 94.48%\n   New best val acc: 94.48% (model saved)\nEpoch 20/50 - Train Loss: 1.9378 | Val Acc: 93.65%\n  No improvement. Patience: 1/10\nEpoch 21/50 - Train Loss: 2.0029 | Val Acc: 94.97%\n   New best val acc: 94.97% (model saved)\nEpoch 22/50 - Train Loss: 2.0007 | Val Acc: 93.98%\n  No improvement. Patience: 1/10\nEpoch 23/50 - Train Loss: 1.9300 | Val Acc: 94.81%\n  No improvement. Patience: 2/10\nEpoch 24/50 - Train Loss: 1.9863 | Val Acc: 95.22%\n   New best val acc: 95.22% (model saved)\nEpoch 25/50 - Train Loss: 1.9446 | Val Acc: 94.72%\n  No improvement. Patience: 1/10\nEpoch 26/50 - Train Loss: 2.0225 | Val Acc: 95.14%\n  No improvement. Patience: 2/10\nEpoch 27/50 - Train Loss: 1.9666 | Val Acc: 94.31%\n  No improvement. Patience: 3/10\nEpoch 28/50 - Train Loss: 1.9581 | Val Acc: 94.06%\n  No improvement. Patience: 4/10\nEpoch 29/50 - Train Loss: 1.8892 | Val Acc: 95.14%\n  No improvement. Patience: 5/10\nEpoch 30/50 - Train Loss: 1.9711 | Val Acc: 94.81%\n  No improvement. Patience: 6/10\nEpoch 31/50 - Train Loss: 1.8958 | Val Acc: 94.31%\n  No improvement. Patience: 7/10\nEpoch 32/50 - Train Loss: 1.9171 | Val Acc: 94.64%\n  No improvement. Patience: 8/10\nEpoch 33/50 - Train Loss: 1.9689 | Val Acc: 94.56%\n  No improvement. Patience: 9/10\nEpoch 34/50 - Train Loss: 1.9084 | Val Acc: 95.05%\n  No improvement. Patience: 10/10\n Early stopping at epoch 34. Best Val Acc: 95.22%\n\n Final Test Accuracy on sketch: 66.23%\n","output_type":"stream"}],"execution_count":1}]}