# -*- coding: utf-8 -*-
"""clip-domain-generalization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vfqAJX8z8IGfjR0y__JeAEbEW5vSWTT9
"""

!pip install open_clip_torch

"""# Images per domain#"""

import os

root_dir = "/kaggle/input/pacs-dataset/kfold"
domains = ["photo", "art_painting", "cartoon", "sketch"]

for domain in domains:
    domain_path = os.path.join(root_dir, domain)
    count = 0
    for cls in os.listdir(domain_path):
        cls_path = os.path.join(domain_path, cls)
        count += len(os.listdir(cls_path))
    print(f"{domain} has {count} images")

"""**Clip domain generalization using patience learning(test on cartoon)**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import open_clip

device = "cuda" if torch.cuda.is_available() else "cpu"


clip_model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')
clip_model.eval().to(device)
for param in clip_model.parameters():
    param.requires_grad = False  # Freeze CLIP weights


class CLIPMLPClassifier(nn.Module):
    def __init__(self, clip_model, num_classes):
        super().__init__()
        self.clip = clip_model
        self.mlp = nn.Sequential(
            nn.Linear(self.clip.visual.output_dim, 256),
            nn.ReLU(),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        with torch.no_grad():
            feats = self.clip.encode_image(x)
        return self.mlp(feats)


def get_loader(domains, root, batch_size=32, shuffle=False):
    dataset = []
    for domain in domains:
        ds = datasets.ImageFolder(os.path.join(root, domain), transform=preprocess)
        dataset.extend(ds.samples)
    base_ds = datasets.ImageFolder(os.path.join(root, domains[0]), transform=preprocess)
    base_ds.samples = dataset
    loader = DataLoader(base_ds, batch_size=batch_size, shuffle=shuffle)
    return loader, len(base_ds.classes)

PACS_PATH = "/kaggle/input/pacs-dataset/kfold"
train_domains = ["photo", "art_painting", "sketch"]
test_domain = "cartoon"

train_loader, num_classes = get_loader(train_domains, root=PACS_PATH, shuffle=True)
test_loader, _ = get_loader([test_domain], root=PACS_PATH, shuffle=False)


model = CLIPMLPClassifier(clip_model, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.mlp.parameters(), lr=1e-4)

# Early stopping
best_acc = 0
wait = 0
patience = 10
best_model_state = None


for epoch in range(50):
    model.train()
    total_loss = 0

    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1} - Training"):
        imgs, labels = imgs.to(device), labels.to(device)
        logits = model(imgs)
        loss = criterion(logits, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1} - Training Loss: {total_loss:.4f}")


    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    acc = 100 * correct / total
    print(f"Test Accuracy on '{test_domain}': {acc:.2f}%")

    # Early stopping check
    if acc > best_acc:
        best_acc = acc
        best_model_state = model.state_dict()
        wait = 0
        print("Accuracy improved. Model saved.")
    else:
        wait += 1
        print(f"No improvement. Wait count: {wait}/{patience}")
        if wait >= patience:
            print("Early stopping triggered.")
            break


if best_model_state:
    model.load_state_dict(best_model_state)
    print(f"Best model with {best_acc:.2f}% accuracy loaded.")

"""**Clip domain generalization using patience learning(test on art_painting)**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import open_clip

device = "cuda" if torch.cuda.is_available() else "cpu"


clip_model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')
clip_model.eval().to(device)
for param in clip_model.parameters():
    param.requires_grad = False


class CLIPMLPClassifier(nn.Module):
    def __init__(self, clip_model, num_classes):
        super().__init__()
        self.clip = clip_model
        self.mlp = nn.Sequential(
            nn.Linear(self.clip.visual.output_dim, 256),
            nn.ReLU(),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        with torch.no_grad():
            feats = self.clip.encode_image(x)
        return self.mlp(feats)


def get_loader(domains, root, batch_size=32, shuffle=False):
    dataset = []
    for domain in domains:
        ds = datasets.ImageFolder(os.path.join(root, domain), transform=preprocess)
        dataset.extend(ds.samples)
    base_ds = datasets.ImageFolder(os.path.join(root, domains[0]), transform=preprocess)
    base_ds.samples = dataset
    loader = DataLoader(base_ds, batch_size=batch_size, shuffle=shuffle)
    return loader, len(base_ds.classes)

PACS_PATH = "/kaggle/input/pacs-dataset/kfold"
train_domains = ["photo", "cartoon", "sketch"]
test_domain = "art_painting"

train_loader, num_classes = get_loader(train_domains, root=PACS_PATH, shuffle=True)
test_loader, _ = get_loader([test_domain], root=PACS_PATH, shuffle=False)


model = CLIPMLPClassifier(clip_model, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.mlp.parameters(), lr=1e-4)

# Early stopping
best_acc = 0
wait = 0
patience = 10
best_model_state = None


for epoch in range(50):
    model.train()
    total_loss = 0

    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1} - Training"):
        imgs, labels = imgs.to(device), labels.to(device)
        logits = model(imgs)
        loss = criterion(logits, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1} - Training Loss: {total_loss:.4f}")


    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    acc = 100 * correct / total
    print(f"Test Accuracy on '{test_domain}': {acc:.2f}%")

    # Early stopping check
    if acc > best_acc:
        best_acc = acc
        best_model_state = model.state_dict()
        wait = 0
        print("Accuracy improved. Model saved.")
    else:
        wait += 1
        print(f"No improvement. Wait count: {wait}/{patience}")
        if wait >= patience:
            print("Early stopping triggered.")
            break


if best_model_state:
    model.load_state_dict(best_model_state)
    print(f"Best model with {best_acc:.2f}% accuracy loaded.")

"""**Domain Generalization using CLIP(test on cartoon**)"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import open_clip

device = "cuda" if torch.cuda.is_available() else "cpu"


clip_model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')
clip_model.eval().to(device)
for param in clip_model.parameters():
    param.requires_grad = False  # freeze CLIP

#  classifier  (512 → 256 → 7)
class CLIPMLPClassifier(nn.Module):
    def __init__(self, clip_model, num_classes):
        super().__init__()
        self.clip = clip_model
        self.mlp = nn.Sequential(
            nn.Linear(self.clip.visual.output_dim, 256),
            nn.ReLU(),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        with torch.no_grad():
            feats = self.clip.encode_image(x)
        return self.mlp(feats)


def get_loader(domains, root, batch_size=32, shuffle=False):
    dataset = []
    for domain in domains:
        ds = datasets.ImageFolder(os.path.join(root, domain), transform=preprocess)
        dataset.extend(ds.samples)
    base_ds = datasets.ImageFolder(os.path.join(root, domains[0]), transform=preprocess)
    base_ds.samples = dataset
    loader = DataLoader(base_ds, batch_size=batch_size, shuffle=shuffle)
    return loader, len(base_ds.classes)


PACS_PATH = "/kaggle/input/pacs-dataset/kfold"
train_domains = ["photo", "art_painting", "sketch"]
test_domain = "cartoon"

train_loader, num_classes = get_loader(train_domains, root=PACS_PATH, shuffle=True)
test_loader, _ = get_loader([test_domain], root=PACS_PATH, shuffle=False)


model = CLIPMLPClassifier(clip_model, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.mlp.parameters(), lr=1e-4)

# Train + evaluate
for epoch in range(20):
    model.train()
    total_loss = 0

    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1} [Training]"):
        imgs, labels = imgs.to(device), labels.to(device)
        logits = model(imgs)
        loss = criterion(logits, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"\nEpoch {epoch+1} Training Loss: {total_loss:.4f}")


    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    acc = 100 * correct / total
    print(f"Test Accuracy on '{test_domain}': {acc:.2f}%\n")

"""**Domain Generalization using CLIP(on art_painting**)"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import open_clip

device = "cuda" if torch.cuda.is_available() else "cpu"


clip_model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')
clip_model.eval().to(device)
for param in clip_model.parameters():
    param.requires_grad = False

# classifier  (512 → 256 → 7)
class CLIPMLPClassifier(nn.Module):
    def __init__(self, clip_model, num_classes):
        super().__init__()
        self.clip = clip_model
        self.mlp = nn.Sequential(
            nn.Linear(self.clip.visual.output_dim, 256),
            nn.ReLU(),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        with torch.no_grad():
            feats = self.clip.encode_image(x)
        return self.mlp(feats)


def get_loader(domains, root, batch_size=32, shuffle=False):
    dataset = []
    for domain in domains:
        ds = datasets.ImageFolder(os.path.join(root, domain), transform=preprocess)
        dataset.extend(ds.samples)
    base_ds = datasets.ImageFolder(os.path.join(root, domains[0]), transform=preprocess)
    base_ds.samples = dataset
    loader = DataLoader(base_ds, batch_size=batch_size, shuffle=shuffle)
    return loader, len(base_ds.classes)


PACS_PATH = "/kaggle/input/pacs-dataset/kfold"
train_domains = ["cartoon", "photo", "sketch"]
test_domain = "art_painting"


train_loader, num_classes = get_loader(train_domains, root=PACS_PATH, shuffle=True)
test_loader, _ = get_loader([test_domain], root=PACS_PATH, shuffle=False)


model = CLIPMLPClassifier(clip_model, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.mlp.parameters(), lr=1e-4)

# Train + evaluate
for epoch in range(20):
    model.train()
    total_loss = 0

    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1} [Training]"):
        imgs, labels = imgs.to(device), labels.to(device)
        logits = model(imgs)
        loss = criterion(logits, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"\nEpoch {epoch+1} Training Loss: {total_loss:.4f}")


    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    acc = 100 * correct / total
    print(f"Test Accuracy on '{test_domain}': {acc:.2f}%\n")